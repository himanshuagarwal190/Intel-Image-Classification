{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport os\nimport cv2\nfrom keras.utils import np_utils","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading data method\ndef load_data(path):\n    labels = []\n    images = []\n    size = (150,150)\n    for i in os.listdir(path):\n        folder = path + '/' + i\n        for j in os.listdir(folder):\n            img_path = folder + '/' + j\n            temp_img = cv2.imread(img_path)\n            temp_img = cv2.resize(temp_img, size)\n            temp_label = i\n            images.append(temp_img)\n            labels.append(temp_label)\n    images = np.array(images, dtype = 'float32')/255\n    labels = np.array(labels)\n    return images, labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calling load_data method\nx_train, y_train = load_data('/kaggle/input/intel-image-classification/seg_train/seg_train')\nx_test, y_test = load_data('/kaggle/input/intel-image-classification/seg_test/seg_test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting random 25 images\nplt.figure(figsize=(25,25))\nfor i in range(1,25):\n    random = np.random.randint(x_train.shape[0])\n    plt.subplot(5,5,i)\n    plt.imshow(x_train[random])\n    plt.title(y_train[random])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking if each class contains equal number of images\nlabels = os.listdir('/kaggle/input/intel-image-classification/seg_train/seg_train')\nlabel_count = {}\nfor i in labels:\n    path = os.listdir('/kaggle/input/intel-image-classification/seg_train/seg_train/' + i)\n    label_count.update({i:len(path)})\nplt.bar(label_count.keys(),label_count.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One hot encoding labels\ndef one_hot(data):\n    y = []\n    for nb, lb in enumerate(labels):\n        for i in data:\n            if i == lb:\n                y.append(nb)\n    y = np_utils.to_categorical(y, len(labels))\n    return y\ny_train = one_hot(y_train)\ny_test = one_hot(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shuffling training and testing data\nfrom sklearn.utils import shuffle\nx_train, y_train = shuffle(x_train, y_train)\nx_test, y_test = shuffle(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing Keras Libraries\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Dense, Activation, Flatten, Dropout\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.applications.vgg16 import VGG16\nfrom keras.regularizers import Regularizer,l2\nfrom keras.applications.resnet50 import ResNet50\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = Sequential()\nmodel1.add(Conv2D(64, (3,3), activation='relu', input_shape=x_train.shape[1:]))\nmodel1.add(Conv2D(128,(3,3), activation='relu'))\nmodel1.add(MaxPool2D(2,2))\nmodel1.add(Conv2D(150,(3,3), activation='relu'))\nmodel1.add(MaxPool2D(2,2))\nmodel1.add(Flatten())\nmodel1.add(Dense(128))\nmodel1.add(Dropout(0.3))\nmodel1.add(Dense(len(labels), activation='softmax'))\nmodel1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\ncheckpoint1 = [ModelCheckpoint('intel_weights1.hdf5', save_best_only=True, monitor='val_loss', mode='auto', verbose=1)]\nmodel1.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1.fit(x_train,y_train, epochs = 10, batch_size=32, validation_split=0.2, verbose = 1, callbacks=checkpoint1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score1 = model1.evaluate(x_test,y_test)\nprint('Accuracy for self created model: ', score1[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = Sequential()\nvgg = VGG16(weights='imagenet', include_top=False, input_shape=x_train.shape[1:])\nvgg.trainable=False\nmodel2.add(vgg)\nmodel2.add(Conv2D(128,(3,3), activation='relu'))\nmodel2.add(Flatten())\nmodel2.add(Dense(128,activation='relu',  activity_regularizer=l2(0.001)))\nmodel2.add(Dropout(0.3))\nmodel2.add(Dense(len(labels), activation='softmax'))\nmodel2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\ncheckpoint2 = [ModelCheckpoint('intel_weights2.hdf5', save_best_only=True, monitor='val_loss', mode='auto', verbose=1)]\nmodel2.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2.fit(x_train,y_train, epochs = 10, batch_size=32, validation_split=0.2, verbose = 1, callbacks=checkpoint2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score2 = model2.evaluate(x_test,y_test)\nprint('Accuracy for VGG16 model: ', score2[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model3 = Sequential()\nresnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=x_train.shape[1:])\nresnet50.trainable=False\nmodel3.add(resnet50)\nmodel3.add(Conv2D(128,(3,3), activation='relu'))\nmodel3.add(Flatten())\nmodel3.add(Dense(128,activation='relu',  activity_regularizer=l2(0.001)))\nmodel3.add(Dropout(0.3))\nmodel3.add(Dense(128,activation='relu'))\nmodel3.add(Dropout(0.2))\nmodel3.add(Dense(len(labels), activation='softmax'))\nmodel3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\ncheckpoint3 = [ModelCheckpoint('intel_weights3.hdf5', save_best_only=True, monitor='val_loss', mode='auto', verbose=1)]\nmodel3.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model3.fit(x_train,y_train, epochs = 10, batch_size=32, validation_split=0.2, verbose = 1, callbacks=checkpoint3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score3 = model3.evaluate(x_test,y_test)\nprint('Accuracy for ResNet model: ', score3[1])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}